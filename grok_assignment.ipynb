{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#  env + model config\n",
        "import os, json, re, getpass\n",
        "from jsonschema import Draft7Validator\n",
        "import openai\n",
        "import pandas as pd\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "\n",
        "# Secure API key (DO NOT hardcode; paste at runtime)\n",
        "if \"OPENAI_API_KEY\" not in os.environ or not os.environ[\"OPENAI_API_KEY\"]:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Paste your GROQ API key (hidden): \").strip()\n",
        "\n",
        "BASE_URL = os.environ.get(\"BASE_URL\", \"https://api.groq.com/openai/v1\")\n",
        "MODEL = \"llama-3.1-8b-instant\"   # change to \"llama-3.1-70b\" if available for final runs\n"
      ],
      "metadata": {
        "id": "N4A-JRRz8oAj"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------------------- CORE ENGINE --------------------------------------------------------------------------------------------------\n",
        "import os, json, re\n",
        "import openai\n",
        "\n",
        "# Cell 2: Core extractor (replace previous versions)\n",
        "schema = {\n",
        "    \"name\": \"extract_user_info\",\n",
        "    \"description\": \"Extract name, email, phone, location and age from free text\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"name\": {\"oneOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}]},\n",
        "            \"email\": {\"oneOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}]},\n",
        "            \"phone\": {\"oneOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}]},\n",
        "            \"location\": {\"oneOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}]},\n",
        "            \"age\": {\"oneOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}]}\n",
        "        },\n",
        "        \"required\": []\n",
        "    }\n",
        "}\n",
        "\n",
        "# small regex helpers\n",
        "_email_re = re.compile(r\"[\\w\\.-]+@[\\w\\.-]+\\.\\w+\")\n",
        "_phone_re = re.compile(r\"(?:\\+?\\d{1,3}[-.\\s]?)?(?:\\d{2,4}[-.\\s]?){1,4}\\d{3,4}\")\n",
        "\n",
        "def _normalize_value(val):\n",
        "    if val is None: return None\n",
        "    if isinstance(val, str):\n",
        "        s = val.strip()\n",
        "        if s == \"\" or s.lower() in (\"none\",\"null\",\"n/a\",\"na\"): return None\n",
        "        if re.fullmatch(r\"\\d+\", s):\n",
        "            try: return int(s)\n",
        "            except: return s\n",
        "        return s\n",
        "    if isinstance(val, (int, float)):\n",
        "        return int(val) if int(val) == val else val\n",
        "    return val\n",
        "\n",
        "def _parse_json_like(obj):\n",
        "    if obj is None: return {}\n",
        "    if isinstance(obj, dict): return obj\n",
        "    txt = str(obj)\n",
        "    try:\n",
        "        return json.loads(txt)\n",
        "    except Exception:\n",
        "        m = re.search(r\"\\{[\\s\\S]*\\}\", txt)\n",
        "        if m:\n",
        "            try: return json.loads(m.group(0))\n",
        "            except: return {}\n",
        "    return {}\n",
        "\n",
        "def _clean_and_coerce(parsed):\n",
        "    keys = list(schema[\"parameters\"][\"properties\"].keys())\n",
        "    cleaned = {k: None for k in keys}\n",
        "    for k,v in parsed.items():\n",
        "        if k not in keys: continue\n",
        "        norm = _normalize_value(v)\n",
        "        if k == \"age\":\n",
        "            if norm is None: cleaned[k] = None\n",
        "            elif isinstance(norm,int): cleaned[k] = norm\n",
        "            else:\n",
        "                try: cleaned[k] = int(str(norm).strip())\n",
        "                except: cleaned[k] = None\n",
        "        else:\n",
        "            cleaned[k] = norm\n",
        "    return cleaned\n",
        "\n",
        "def _validate(cleaned):\n",
        "    validator = Draft7Validator(schema[\"parameters\"])\n",
        "    errs = [e.message for e in sorted(validator.iter_errors(cleaned), key=lambda x: x.path)]\n",
        "    return (len(errs)==0, errs)\n",
        "\n",
        "def _regex_fallback(text):\n",
        "    \"\"\"Return any simple email/phone found (fallback).\"\"\"\n",
        "    email = _email_re.search(text)\n",
        "    phone = _phone_re.search(text)\n",
        "    return {\"email\": email.group(0) if email else None, \"phone\": phone.group(0) if phone else None}\n",
        "\n",
        "def _fallback_extract_text_json(chat_text, model_name, base_url, verbose=False):\n",
        "    client = openai.OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"], base_url=base_url)\n",
        "    prompt = (\n",
        "        \"Extract name, email, phone, location, and age from the text. \"\n",
        "        \"Return EXACTLY a JSON object with keys: name, email, phone, location, age. Use null for missing fields.\\n\\n\"\n",
        "        f\"Text: {chat_text}\\n\\nJSON:\"\n",
        "    )\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[{\"role\":\"user\",\"content\":prompt}],\n",
        "            temperature=0.0,\n",
        "            max_tokens=300\n",
        "        )\n",
        "    except Exception as e:\n",
        "        if verbose: print(\"Fallback request error:\", e)\n",
        "        return {\"raw\": {}, \"valid\": False, \"errors\": [f\"Fallback request error: {e}\"], \"warnings\": []}\n",
        "    try:\n",
        "        if isinstance(resp, dict):\n",
        "            content = resp.get(\"choices\",[{}])[0].get(\"message\",{}).get(\"content\",\"\") or \"\"\n",
        "        else:\n",
        "            content = getattr(resp.choices[0].message,\"content\",\"\") or \"\"\n",
        "    except Exception:\n",
        "        content = \"\"\n",
        "    parsed = _parse_json_like(content)\n",
        "    cleaned = _clean_and_coerce(parsed)\n",
        "    valid, errors = _validate(cleaned)\n",
        "    return {\"raw\": cleaned, \"valid\": valid, \"errors\": errors, \"warnings\": []}\n",
        "\n",
        "def extract_info(chat_text, model_name=MODEL, base_url=BASE_URL, use_fallback=True, verbose=False):\n",
        "    client = openai.OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"], base_url=base_url)\n",
        "    warnings = []\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[\n",
        "                {\"role\":\"system\",\"content\":\"You are a JSON extractor. Return a function call with arguments matching the provided schema. Use null for missing fields.\"},\n",
        "                {\"role\":\"user\",\"content\":f\"Extract name, email, phone, location, age from: {chat_text}\"}\n",
        "            ],\n",
        "            functions=[schema],\n",
        "            function_call=\"auto\",\n",
        "            temperature=0.0,\n",
        "            max_tokens=300\n",
        "        )\n",
        "    except Exception as e:\n",
        "        if verbose: print(\"Primary call error:\", e)\n",
        "        if use_fallback:\n",
        "            # regex quick-fallback then text-JSON fallback\n",
        "            basic = _regex_fallback(chat_text)\n",
        "            fb = _fallback_extract_text_json(chat_text, model_name, base_url, verbose)\n",
        "            # merge regex results if fb missing\n",
        "            for k in (\"email\",\"phone\"):\n",
        "                if fb[\"raw\"].get(k) is None and basic.get(k): fb[\"raw\"][k] = basic[k]\n",
        "            return fb\n",
        "        return {\"raw\": {}, \"valid\": False, \"errors\":[f\"Request error: {e}\"], \"warnings\": []}\n",
        "\n",
        "    # parse function_call args if present\n",
        "    func_args_raw = None\n",
        "    try:\n",
        "        if isinstance(resp, dict):\n",
        "            choice = resp.get(\"choices\",[{}])[0]\n",
        "            msg = choice.get(\"message\",{}) or {}\n",
        "            fc = msg.get(\"function_call\")\n",
        "            func_args_raw = fc.get(\"arguments\") if fc else None\n",
        "        else:\n",
        "            choice = resp.choices[0]\n",
        "            fc = getattr(choice.message, \"function_call\", None)\n",
        "            func_args_raw = getattr(fc, \"arguments\", None) if fc else None\n",
        "    except Exception as e:\n",
        "        if verbose: print(\"Response parse error:\", e)\n",
        "        func_args_raw = None\n",
        "\n",
        "    parsed = {}\n",
        "    if func_args_raw:\n",
        "        parsed = _parse_json_like(func_args_raw)\n",
        "    else:\n",
        "        # try to parse message content\n",
        "        try:\n",
        "            if isinstance(resp, dict):\n",
        "                content = resp.get(\"choices\",[{}])[0].get(\"message\",{}).get(\"content\",\"\") or \"\"\n",
        "            else:\n",
        "                content = getattr(resp.choices[0].message,\"content\",\"\") or \"\"\n",
        "            parsed = _parse_json_like(content)\n",
        "        except Exception:\n",
        "            parsed = {}\n",
        "\n",
        "    # if still empty, fallback\n",
        "    if not parsed and use_fallback:\n",
        "        basic = _regex_fallback(chat_text)\n",
        "        fb = _fallback_extract_text_json(chat_text, model_name, base_url, verbose)\n",
        "        # merge regex\n",
        "        for k in (\"email\",\"phone\"):\n",
        "            if fb[\"raw\"].get(k) is None and basic.get(k): fb[\"raw\"][k] = basic[k]\n",
        "        return fb\n",
        "\n",
        "    cleaned = _clean_and_coerce(parsed)\n",
        "    valid, errors = _validate(cleaned)\n",
        "    return {\"raw\": cleaned, \"valid\": valid, \"errors\": errors, \"warnings\": warnings}\n"
      ],
      "metadata": {
        "id": "S5fzFoKMqefG"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBQWjg_gek81",
        "outputId": "2624b0bb-894b-45b5-e054-bd0cf3aacaf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.106.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pJuNz_gxjvuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "# Set API key securely using getpass or Colab secrets\n",
        "# The API key should not be hardcoded directly in the notebook for security.\n",
        "# Assuming the API key is set using getpass in a previous cell (0YT6Gq5lohl3)\n",
        "# If you are not using getpass, you should use Colab secrets instead.\n",
        "\n",
        "# Use Groq API base\n",
        "openai.api_base = \"https://api.groq.com/openai/v1\""
      ],
      "metadata": {
        "id": "2bU5gq0ajwQB"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = []\n",
        "\n",
        "def add_message(role, content):\n",
        "    conversation.append({\"role\": role, \"content\": content})\n"
      ],
      "metadata": {
        "id": "E6FuRtqTkSZl"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Demonstration for Task 1: Conversation Manager ---\n",
        "\n",
        "# Initialize with summarization every 3rd user input\n",
        "# Corrected class name and parameters to match ConversationManager definition\n",
        "engine = ConversationManager(summarize_every_k=3, base_url=BASE_URL, api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "# Simulate multiple exchanges\n",
        "sample_chats = [\n",
        "    (\"user\", \"Hi, I want to know about AI.\"),\n",
        "    (\"assistant\", \"Sure! AI stands for Artificial Intelligence.\"),\n",
        "    (\"user\", \"Can you also tell me about Machine Learning?\"),\n",
        "    (\"assistant\", \"Yes, ML is a subset of AI that focuses on pattern recognition.\"),\n",
        "    (\"user\", \"What about Deep Learning?\"),\n",
        "    (\"assistant\", \"Deep Learning uses neural networks with many layers.\"),\n",
        "    (\"user\", \"Summarize everything so far.\"), # This last message won't trigger summarization based on k=3 user messages\n",
        "]\n",
        "\n",
        "# Run through conversation\n",
        "for role, text in sample_chats:\n",
        "    engine.add(role, text) # Use the 'add' method of ConversationManager\n",
        "    print(f\"\\n[{role.upper()}]: {text}\")\n",
        "    print(\"---- Current History ----\")\n",
        "    # ConversationManager stores messages in the 'messages' attribute\n",
        "    print(engine.messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM0BGrwQdtXQ",
        "outputId": "2b6c11ea-44ce-4b0e-cc91-89ee2d815767"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[USER]: Hi, I want to know about AI.\n",
            "---- Current History ----\n",
            "[{'role': 'user', 'content': 'Hi, I want to know about AI.'}]\n",
            "\n",
            "[ASSISTANT]: Sure! AI stands for Artificial Intelligence.\n",
            "---- Current History ----\n",
            "[{'role': 'user', 'content': 'Hi, I want to know about AI.'}, {'role': 'assistant', 'content': 'Sure! AI stands for Artificial Intelligence.'}]\n",
            "\n",
            "[USER]: Can you also tell me about Machine Learning?\n",
            "---- Current History ----\n",
            "[{'role': 'user', 'content': 'Hi, I want to know about AI.'}, {'role': 'assistant', 'content': 'Sure! AI stands for Artificial Intelligence.'}, {'role': 'user', 'content': 'Can you also tell me about Machine Learning?'}]\n",
            "\n",
            "[ASSISTANT]: Yes, ML is a subset of AI that focuses on pattern recognition.\n",
            "---- Current History ----\n",
            "[{'role': 'user', 'content': 'Hi, I want to know about AI.'}, {'role': 'assistant', 'content': 'Sure! AI stands for Artificial Intelligence.'}, {'role': 'user', 'content': 'Can you also tell me about Machine Learning?'}, {'role': 'assistant', 'content': 'Yes, ML is a subset of AI that focuses on pattern recognition.'}]\n",
            "\n",
            "[USER]: What about Deep Learning?\n",
            "---- Current History ----\n",
            "[{'role': 'system', 'content': 'Conversation summary'}, {'role': 'assistant', 'content': \"Here's a summary of the conversation:\\n\\n- The conversation is about Artificial Intelligence (AI).\\n- AI has a subset called Machine Learning (ML) that focuses on pattern recognition.\\n- The user also inquired about Deep Learning, but it was not explicitly defined in the conversation.\"}]\n",
            "\n",
            "[ASSISTANT]: Deep Learning uses neural networks with many layers.\n",
            "---- Current History ----\n",
            "[{'role': 'system', 'content': 'Conversation summary'}, {'role': 'assistant', 'content': \"Here's a summary of the conversation:\\n\\n- The conversation is about Artificial Intelligence (AI).\\n- AI has a subset called Machine Learning (ML) that focuses on pattern recognition.\\n- The user also inquired about Deep Learning, but it was not explicitly defined in the conversation.\"}, {'role': 'assistant', 'content': 'Deep Learning uses neural networks with many layers.'}]\n",
            "\n",
            "[USER]: Summarize everything so far.\n",
            "---- Current History ----\n",
            "[{'role': 'system', 'content': 'Conversation summary'}, {'role': 'assistant', 'content': \"Here's a summary of the conversation:\\n\\n- The conversation is about Artificial Intelligence (AI).\\n- AI has a subset called Machine Learning (ML) that focuses on pattern recognition.\\n- The user also inquired about Deep Learning, but it was not explicitly defined in the conversation.\"}, {'role': 'assistant', 'content': 'Deep Learning uses neural networks with many layers.'}, {'role': 'user', 'content': 'Summarize everything so far.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1 demo: show history, truncation, summarization after k\n",
        "cm = ConversationManager(model_name=MODEL, summarize_every_k=3)\n",
        "\n",
        "# feed exchanges (6-7)\n",
        "pairs = [\n",
        "    (\"user\",\"Hi, I need help with my resume.\"),\n",
        "    (\"assistant\",\"Sure, what role?\"),\n",
        "    (\"user\",\"Backend developer role, 2 years experience.\"),\n",
        "    (\"assistant\",\"What technologies?\"),\n",
        "    (\"user\",\"Python, Flask, PostgreSQL.\"),\n",
        "    (\"assistant\",\"Noted.\"),\n",
        "    (\"user\",\"Please summarize my profile.\")\n",
        "]\n",
        "\n",
        "for role, text in pairs:\n",
        "    cm.add(role, text)\n",
        "    print(f\"Added {role}: {text}\")\n",
        "    print(\"History (preview):\")\n",
        "    for m in cm.messages:\n",
        "        print(\"-\", m[\"role\"], \":\", m[\"content\"][:120])\n",
        "    print(\"----\\n\")\n",
        "\n",
        "# Demonstrate truncation by turns\n",
        "cm2 = ConversationManager(model_name=MODEL)\n",
        "for role,text in pairs*2:\n",
        "    cm2.add(role,text)\n",
        "print(\"Before truncate_by_turns:\", len(cm2.messages))\n",
        "cm2.truncate_by_turns(4)\n",
        "print(\"After truncate_by_turns(4):\", len(cm2.messages))\n",
        "\n",
        "# Demonstrate truncation by chars\n",
        "cm3 = ConversationManager(model_name=MODEL)\n",
        "for role,text in pairs*2:\n",
        "    cm3.add(role,text)\n",
        "print(\"Chars before:\", sum(len(m[\"content\"]) for m in cm3.messages))\n",
        "cm3.truncate_by_chars(120)\n",
        "print(\"Chars after:\", sum(len(m[\"content\"]) for m in cm3.messages))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I-lVK4L91lo",
        "outputId": "720a48f7-9d75-486e-cbcd-2cc4b375118d"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user: Hi, I need help with my resume.\n",
            "History (preview):\n",
            "- user : Hi, I need help with my resume.\n",
            "----\n",
            "\n",
            "Added assistant: Sure, what role?\n",
            "History (preview):\n",
            "- user : Hi, I need help with my resume.\n",
            "- assistant : Sure, what role?\n",
            "----\n",
            "\n",
            "Added user: Backend developer role, 2 years experience.\n",
            "History (preview):\n",
            "- user : Hi, I need help with my resume.\n",
            "- assistant : Sure, what role?\n",
            "- user : Backend developer role, 2 years experience.\n",
            "----\n",
            "\n",
            "Added assistant: What technologies?\n",
            "History (preview):\n",
            "- user : Hi, I need help with my resume.\n",
            "- assistant : Sure, what role?\n",
            "- user : Backend developer role, 2 years experience.\n",
            "- assistant : What technologies?\n",
            "----\n",
            "\n",
            "Error: API key is not set in ConversationManager.\n",
            "Added user: Python, Flask, PostgreSQL.\n",
            "History (preview):\n",
            "- system : Conversation summary\n",
            "- assistant : Summary unavailable: API key missing.\n",
            "----\n",
            "\n",
            "Added assistant: Noted.\n",
            "History (preview):\n",
            "- system : Conversation summary\n",
            "- assistant : Summary unavailable: API key missing.\n",
            "- assistant : Noted.\n",
            "----\n",
            "\n",
            "Added user: Please summarize my profile.\n",
            "History (preview):\n",
            "- system : Conversation summary\n",
            "- assistant : Summary unavailable: API key missing.\n",
            "- assistant : Noted.\n",
            "- user : Please summarize my profile.\n",
            "----\n",
            "\n",
            "Before truncate_by_turns: 14\n",
            "After truncate_by_turns(4): 4\n",
            "Chars before: 336\n",
            "Chars after: 78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1 Demonstration: Conversation Manager\n",
        "Below we simulate 6–7 exchanges between a user and an assistant to show:\n",
        "- Full history retention  \n",
        "- Truncation by last N messages  \n",
        "- Truncation by character length  \n",
        "- Summarization every k-th run (k=3 in this example)\n"
      ],
      "metadata": {
        "id": "DOBdVSTGeAgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def truncate_by_turns(history, n=4):\n",
        "    return history[-n:]\n",
        "\n",
        "def truncate_by_length(history, max_chars=200):\n",
        "    text = \" \".join([m[\"content\"] for m in history])\n",
        "    return text[:max_chars]\n"
      ],
      "metadata": {
        "id": "2_EHLTrkk9c9"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_conversation(history):\n",
        "    client = openai.OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"], base_url=\"https://api.groq.com/openai/v1\")\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",  # Groq LLM - Updated model\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Summarize the conversation concisely.\"},\n",
        "            {\"role\": \"user\", \"content\": str(history)}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "lg8t7cnxlFEo"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_count = 0\n",
        "\n",
        "def add_and_maybe_summarize(role, content, k=3):\n",
        "    global run_count, conversation\n",
        "    add_message(role, content)\n",
        "    run_count += 1\n",
        "    if run_count % k == 0:\n",
        "        summary = summarize_conversation(conversation)\n",
        "        conversation = [{\"role\": \"system\", \"content\": \"Conversation summary\"},\n",
        "                        {\"role\": \"assistant\", \"content\": summary}]\n"
      ],
      "metadata": {
        "id": "pK0aQEE4lGHx"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema = {\n",
        "    \"name\": \"extract_user_info\",\n",
        "    \"description\": \"Extracts user details\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"name\": {\"type\": \"string\"},\n",
        "            \"email\": {\"type\": \"string\"},\n",
        "            \"phone\": {\"type\": \"string\"},\n",
        "            \"location\": {\"type\": \"string\"},\n",
        "            \"age\": {\"type\": \"integer\"}\n",
        "        },\n",
        "        \"required\": [\"name\", \"email\", \"phone\", \"location\", \"age\"]\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "fpsryrOglHYR"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Task 2 Demonstration: Schema-based Extraction\n",
        "\n",
        "Below we test the `extract_info` function using the defined schema on multiple samples.  \n",
        "This shows how user inputs are classified and mapped into structured JSON output.\n"
      ],
      "metadata": {
        "id": "-b7mc0RAg7Pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Demonstration for Task 2: Schema Extraction ---\n",
        "test_samples = [\n",
        "    \"The conference will be held on 25th September 2025 in Hyderabad.\",\n",
        "    \"Book a flight ticket for John Doe from New York to London on October 5, 2025.\",\n",
        "    \"My phone number is 9876543210 and email is test@example.com.\"\n",
        "]\n",
        "\n",
        "for i, sample in enumerate(test_samples, 1):\n",
        "    print(f\"\\n=== Sample {i} ===\")\n",
        "    print(\"Input:\", sample)\n",
        "    result = extract_info(sample)\n",
        "    print(\"Extracted JSON:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzE2uu4rg-sH",
        "outputId": "abd01fd3-d290-4405-9db3-bf6559946ca9"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Sample 1 ===\n",
            "Input: The conference will be held on 25th September 2025 in Hyderabad.\n",
            "Extracted JSON: {'raw': {'name': None, 'email': None, 'phone': None, 'location': 'Hyderabad', 'age': None}, 'valid': False, 'errors': [\"None is not of type 'integer'\", \"None is not of type 'string'\", \"None is not of type 'string'\", \"None is not of type 'string'\"], 'warnings': []}\n",
            "\n",
            "=== Sample 2 ===\n",
            "Input: Book a flight ticket for John Doe from New York to London on October 5, 2025.\n",
            "Extracted JSON: {'raw': {'name': 'John Doe', 'email': None, 'phone': None, 'location': 'New York', 'age': None}, 'valid': False, 'errors': [\"None is not of type 'integer'\", \"None is not of type 'string'\", \"None is not of type 'string'\"], 'warnings': []}\n",
            "\n",
            "=== Sample 3 ===\n",
            "Input: My phone number is 9876543210 and email is test@example.com.\n",
            "Extracted JSON: {'raw': {'name': None, 'email': 'test@example.com', 'phone': 9876543210, 'location': None, 'age': None}, 'valid': False, 'errors': [\"None is not of type 'integer'\", \"None is not of type 'string'\", \"None is not of type 'string'\", \"9876543210 is not of type 'string'\"], 'warnings': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Evaluation for Task 2: Extraction Quality ---\n",
        "expected = [\n",
        "    {\"location\": \"Hyderabad\"},\n",
        "    {\"name\": \"John Doe\", \"location\": \"New York\"},\n",
        "    {\"phone\": \"9876543210\", \"email\": \"test@example.com\"}\n",
        "]\n",
        "\n",
        "print(\"=== Evaluation ===\")\n",
        "correct = 0\n",
        "\n",
        "for i, (exp, sample) in enumerate(zip(expected, test_samples), 1):\n",
        "    result = extract_info(sample)\n",
        "    extracted = result[\"raw\"]\n",
        "\n",
        "    # check overlap between expected and extracted\n",
        "    match = all(extracted.get(k) == v for k, v in exp.items())\n",
        "    print(f\"Sample {i}: Expected {exp}, Got {extracted}, Match={match}\")\n",
        "    if match:\n",
        "        correct += 1\n",
        "\n",
        "print(f\"\\nAccuracy: {correct}/{len(expected)} = {correct/len(expected):.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6BrANWoh2fm",
        "outputId": "5b2db983-5dcb-41b1-c517-116bc8f32ee7"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Evaluation ===\n",
            "Sample 1: Expected {'location': 'Hyderabad'}, Got {'name': None, 'email': None, 'phone': None, 'location': 'Hyderabad', 'age': None}, Match=True\n",
            "Sample 2: Expected {'name': 'John Doe', 'location': 'New York'}, Got {'name': 'John Doe', 'email': None, 'phone': None, 'location': 'New York', 'age': None}, Match=True\n",
            "Sample 3: Expected {'phone': '9876543210', 'email': 'test@example.com'}, Got {'name': None, 'email': 'test@example.com', 'phone': 9876543210, 'location': None, 'age': None}, Match=False\n",
            "\n",
            "Accuracy: 2/3 = 66.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation for the Task 2 demo samples\n",
        "test_samples = [\n",
        "    \"The conference will be held on 25th September 2025 in Hyderabad.\",\n",
        "    \"Book a flight ticket for John Doe from New York to London on October 5, 2025.\",\n",
        "    \"My phone number is 9876543210 and email is test@example.com.\"\n",
        "]\n",
        "\n",
        "expected = [\n",
        "    {\"location\":\"Hyderabad\"},\n",
        "    {\"name\":\"John Doe\", \"location\":\"New York\"},  # adjust expected fields per your chosen ground-truth\n",
        "    {\"phone\":\"9876543210\",\"email\":\"test@example.com\"}\n",
        "]\n",
        "\n",
        "correct = 0\n",
        "for i, sample in enumerate(test_samples):\n",
        "    out = extract_info(sample, model_name=MODEL, use_fallback=True, verbose=False)\n",
        "    got = out[\"raw\"]\n",
        "    exp = expected[i]\n",
        "    match = all((got.get(k) == v) for k,v in exp.items())\n",
        "    print(f\"Sample {i+1} - match={match}\\n  expected={exp}\\n  got={got}\\n  valid={out['valid']}\\n\")\n",
        "    if match: correct += 1\n",
        "\n",
        "print(f\"Accuracy: {correct}/{len(test_samples)} = {correct/len(test_samples):.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAF8yv_u9rta",
        "outputId": "0a3c2bef-a1a8-4d98-b331-a17e76588e0e"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1 - match=True\n",
            "  expected={'location': 'Hyderabad'}\n",
            "  got={'name': None, 'email': None, 'phone': None, 'location': 'Hyderabad', 'age': None}\n",
            "  valid=False\n",
            "\n",
            "Sample 2 - match=True\n",
            "  expected={'name': 'John Doe', 'location': 'New York'}\n",
            "  got={'name': 'John Doe', 'email': None, 'phone': None, 'location': 'New York', 'age': None}\n",
            "  valid=False\n",
            "\n",
            "Sample 3 - match=False\n",
            "  expected={'phone': '9876543210', 'email': 'test@example.com'}\n",
            "  got={'name': None, 'email': 'test@example.com', 'phone': 9876543210, 'location': None, 'age': None}\n",
            "  valid=False\n",
            "\n",
            "Accuracy: 2/3 = 66.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, re\n",
        "import openai\n",
        "\n",
        "# Schema definition outside the function for better practice\n",
        "schema = {\n",
        "    \"name\": \"extract_user_info\",\n",
        "    \"description\": \"Extracts user details\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"name\": {\"type\": \"string\"},\n",
        "            \"email\": {\"type\": \"string\"},\n",
        "            \"phone\": {\"type\": \"string\"},\n",
        "            \"location\": {\"type\": \"string\"},\n",
        "            \"age\": {\"type\": \"integer\"}\n",
        "        },\n",
        "        \"required\": []  # Make all fields optional\n",
        "    }\n",
        "}\n",
        "\n",
        "def extract_info(chat):\n",
        "    client = openai.OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"], base_url=\"https://api.groq.com/openai/v1\")\n",
        "    parsed = {} # Initialize parsed data\n",
        "\n",
        "    try:\n",
        "        warnings = []  # store non-fatal issues here\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"llama-3.1-8b-instant\",  # Updated model\n",
        "            messages=[{\"role\": \"user\", \"content\": chat}],\n",
        "            functions=[schema],\n",
        "            function_call={\"name\": \"extract_user_info\"}\n",
        "        )\n",
        "        if response.choices and response.choices[0].message.function_call:\n",
        "            func_args = response.choices[0].message.function_call.arguments\n",
        "            if isinstance(func_args, str):\n",
        "                try:\n",
        "                    parsed = json.loads(func_args)\n",
        "                except json.JSONDecodeError:\n",
        "                    print(f\"Warning: Could not parse function arguments string as JSON: {func_args}\")\n",
        "                    parsed = {}\n",
        "            elif isinstance(func_args, dict):\n",
        "                parsed = func_args\n",
        "            else:\n",
        "                print(f\"Warning: Unexpected type for function arguments: {type(func_args)}. Raw value: {func_args}\")\n",
        "                parsed = {}\n",
        "\n",
        "    except openai.BadRequestError as e:\n",
        "        print(f\"An API error occurred: {e}\")\n",
        "        error_message = str(e)\n",
        "        failed_generation_match = re.search(r\"'failed_generation': '(.*?)'\", error_message)\n",
        "        if failed_generation_match:\n",
        "            failed_generation_str = failed_generation_match.group(1)\n",
        "            cleaned_json_str = re.sub(r'<function=.*?>(.*?)</function>', r'\\1', failed_generation_str)\n",
        "            try:\n",
        "                parsed = json.loads(cleaned_json_str)\n",
        "                print(f\"Successfully extracted and parsed data from failed_generation: {parsed}\")\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"Warning: Could not parse failed_generation string as JSON: {cleaned_json_str}\")\n",
        "                parsed = {} # Set to empty dict on failure\n",
        "        else:\n",
        "            print(\"Could not find failed_generation in error details. Returning empty data.\")\n",
        "            parsed = {} # Set to empty dict if failed_generation is not found\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        parsed = {} # Set to empty dict for unexpected errors\n",
        "\n",
        "\n",
        "    # Clean up and cast fields to correct types based on schema (applied to both success and error parsing)\n",
        "    cleaned_parsed = {}\n",
        "    for key, value in parsed.items():\n",
        "        if key in schema[\"parameters\"][\"properties\"]:\n",
        "            expected_schema_type = schema[\"parameters\"][\"properties\"][key]\n",
        "            if key == \"age\" and \"oneOf\" in expected_schema_type and {\"type\": \"null\"} in expected_schema_type[\"oneOf\"]:\n",
        "                 # If age can be null, accept None or null from model\n",
        "                 if value is None or value == \"null\":\n",
        "                      cleaned_parsed[key] = None\n",
        "                 elif isinstance(value, (int, float)):\n",
        "                      cleaned_parsed[key] = int(value)\n",
        "                 elif isinstance(value, str) and value.isdigit():\n",
        "                      cleaned_parsed[key] = int(value)\n",
        "                 elif value is not None and value != \"\":\n",
        "                      print(f\"Warning: Could not cast value '{value}' for key '{key}' to integer or null. Skipping.\")\n",
        "            elif expected_schema_type.get(\"type\") == \"integer\":\n",
        "                # Attempt to cast to integer, handle errors and empty strings for standard integers\n",
        "                if isinstance(value, (int, float)):\n",
        "                     cleaned_parsed[key] = int(value)\n",
        "                elif isinstance(value, str) and value.isdigit():\n",
        "                     cleaned_parsed[key] = int(value)\n",
        "                elif value is not None and value != \"\":\n",
        "                     print(f\"Warning: Could not cast value '{value}' for key '{key}' to integer. Skipping.\")\n",
        "            elif \"oneOf\" in expected_schema_type and {\"type\": \"string\"} in expected_schema_type[\"oneOf\"] and {\"type\": \"null\"} in expected_schema_type[\"oneOf\"]:\n",
        "                # Handle fields that can be string or null\n",
        "                if value is None or value == \"null\":\n",
        "                     cleaned_parsed[key] = None\n",
        "                elif value is not None:\n",
        "                     cleaned_parsed[key] = str(value)\n",
        "            elif expected_schema_type.get(\"type\") == \"string\":\n",
        "                 # Ensure string type, convert non-string values if possible\n",
        "                 if value is not None:\n",
        "                      cleaned_parsed[key] = str(value)\n",
        "            else:\n",
        "                # Keep other types as they are or handle specifically if needed\n",
        "                cleaned_parsed[key] = value\n",
        "        else:\n",
        "             # Include keys not in schema if desired, or skip\n",
        "             cleaned_parsed[key] = value\n",
        "\n",
        "\n",
        "    # Validate schema against the cleaned data\n",
        "    # Note: Schema is defined inside the function, which is not ideal practice.\n",
        "    # It's better to define constants like schemas outside functions.\n",
        "    # For this fix, we'll keep it here to avoid modifying other cells.\n",
        "    validator = Draft7Validator(schema[\"parameters\"])\n",
        "    errors = [e.message for e in sorted(validator.iter_errors(cleaned_parsed), key=lambda x: x.path)]\n",
        "\n",
        "    return {\n",
        "        \"raw\": cleaned_parsed,\n",
        "        \"valid\": len(errors) == 0,\n",
        "        \"errors\": errors,\n",
        "        \"warnings\": warnings\n",
        "    }"
      ],
      "metadata": {
        "id": "JbeBdLfRlHLS"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from jsonschema import Draft7Validator\n",
        "\n",
        "# Define the MODEL variable\n",
        "MODEL = \"llama-3.1-8b-instant\"\n",
        "\n",
        "sample_chats = [\n",
        "    \"Hi, I'm Ravi. email: ravi123@gmail.com phone: 9876543210 location: Hyderabad age 23\",\n",
        "    \"Hello — Priya here, priya.jobs@mail.com. I live in Bengaluru, 29 years old.\",\n",
        "    \"Contact: Amit, phone 070-555-1234. Based in Mumbai. No email.\"\n",
        "]\n",
        "\n",
        "print(\"=== Extraction + Validation Demo ===\")\n",
        "for chat in sample_chats:\n",
        "    # Remove use_fallback and verbose if they are not parameters of the current extract_info\n",
        "    # Assuming extract_info from 3nTy9rU-pA8m is the intended one, it takes chat_text, model_name, base_url\n",
        "    # Corrected function call arguments to match extract_info(chat) signature\n",
        "    out = extract_info(chat)\n",
        "    print(\"\\nChat:\", chat)\n",
        "    print(\"Extracted:\", out[\"raw\"])\n",
        "    print(\"Valid?:\", out[\"valid\"])\n",
        "    if out[\"errors\"]:\n",
        "        print(\"Errors:\", out[\"errors\"])\n",
        "    if out.get(\"warnings\"):\n",
        "        print(\"Warnings:\", out[\"warnings\"])\n",
        "\n",
        "    # explicit jsonschema validation (optional double-check)\n",
        "    # Ensure schema is accessible - assuming schema is defined globally or in a reachable cell\n",
        "    # If schema is defined inside extract_info, this outside validation won't work.\n",
        "    # For demonstration, let's assume schema is globally available or defined in a cell above this one.\n",
        "    # If not, this block might cause a NameError for 'schema'.\n",
        "    try:\n",
        "        validator = Draft7Validator(schema[\"parameters\"])\n",
        "        val_errors = [e.message for e in sorted(validator.iter_errors(out[\"raw\"]), key=lambda x: x.path)]\n",
        "        if val_errors:\n",
        "            print(\"Schema validator errors:\", val_errors)\n",
        "    except NameError:\n",
        "        print(\"Skipping explicit jsonschema validation: 'schema' variable is not defined in this scope.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHX4c5S-J7io",
        "outputId": "61b0f524-e353-47fa-8af0-0f7b65bb5dee"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Extraction + Validation Demo ===\n",
            "\n",
            "Chat: Hi, I'm Ravi. email: ravi123@gmail.com phone: 9876543210 location: Hyderabad age 23\n",
            "Extracted: {'age': 23, 'email': 'ravi123@gmail.com', 'location': 'Hyderabad', 'name': 'Ravi', 'phone': '9876543210'}\n",
            "Valid?: True\n",
            "An API error occurred: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=extract_user_info>{\"name\": \"Priya\", \"email\": \"priya.jobs@mail.com\", \"location\": \"Bengaluru\", \"age\": 29, \"phone\": \"Not Specified\", \"name\": \"Priya\"}\"</function>'}}\n",
            "Warning: Could not parse failed_generation string as JSON: {\"name\": \"Priya\", \"email\": \"priya.jobs@mail.com\", \"location\": \"Bengaluru\", \"age\": 29, \"phone\": \"Not Specified\", \"name\": \"Priya\"}\"\n",
            "\n",
            "Chat: Hello — Priya here, priya.jobs@mail.com. I live in Bengaluru, 29 years old.\n",
            "Extracted: {}\n",
            "Valid?: True\n",
            "\n",
            "Chat: Contact: Amit, phone 070-555-1234. Based in Mumbai. No email.\n",
            "Extracted: {'email': '', 'location': 'Mumbai', 'name': 'Amit', 'phone': '070-555-1234'}\n",
            "Valid?: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the extraction function with a sample chat\n",
        "result = extract_info(\n",
        "    \"Hi, my name is Ravi. My email is ravi123@gmail.com, phone is 9876543210. \"\n",
        "    \"I live in Hyderabad and I am 23 years old.\"\n",
        ")\n",
        "\n",
        "print(result)\n",
        "\n",
        "# Add more diverse and complex test cases\n",
        "diverse_samples = [\n",
        "    \"My name is Jane Doe, email: jane.doe@example.com\", # Missing phone, location, age\n",
        "    \"Lives in London, phone: +44 20 1234 5678\", # Missing name, email, age\n",
        "    \"Age is 45\", # Missing name, email, phone, location\n",
        "    \"No info here.\", # No information to extract\n",
        "    \"Name: John Smith, Email: john.smith@web.net, Age: fifty-two\", # Age as text\n",
        "    \"Contact: 555-1234, Location: Paris, France\", # Missing name, email, age, different phone format\n",
        "    \"Email only: test@example.com\", # Only email provided\n",
        "    \"Age: 30 years old, Location: Berlin\", # Age with extra text\n",
        "    \"Name: Alice, Phone: 111-222-3333, Email: alice@mail.org, Location: Sydney, Age: 25\" # All fields\n",
        "]\n",
        "\n",
        "print(\"\\nTesting with diverse inputs:\")\n",
        "for s in diverse_samples:\n",
        "    out = extract_info(s)\n",
        "    print(\"\\nChat:\", s)\n",
        "    print(\"Extracted:\", out) # Print the raw extracted dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4MCuLlfluiJ",
        "outputId": "79227863-84b6-45fe-b40b-2b67769ddd53"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'raw': {'age': 23, 'email': 'ravi123@gmail.com', 'location': 'Hyderabad', 'name': 'Ravi', 'phone': '9876543210'}, 'valid': True, 'errors': [], 'warnings': []}\n",
            "\n",
            "Testing with diverse inputs:\n",
            "\n",
            "Chat: My name is Jane Doe, email: jane.doe@example.com\n",
            "Extracted: {'raw': {'email': 'jane.doe@example.com', 'name': 'Jane Doe'}, 'valid': True, 'errors': [], 'warnings': []}\n",
            "\n",
            "Chat: Lives in London, phone: +44 20 1234 5678\n",
            "Extracted: {'raw': {'location': 'London', 'phone': '+44 20 1234 5678'}, 'valid': True, 'errors': [], 'warnings': []}\n",
            "\n",
            "Chat: Age is 45\n",
            "Extracted: {'raw': {'age': 45, 'email': '', 'location': '', 'name': '', 'phone': ''}, 'valid': True, 'errors': [], 'warnings': []}\n",
            "An API error occurred: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=extract_user_info>{}<function>'}}\n",
            "Warning: Could not parse failed_generation string as JSON: <function=extract_user_info>{}<function>\n",
            "\n",
            "Chat: No info here.\n",
            "Extracted: {'raw': {}, 'valid': True, 'errors': [], 'warnings': []}\n",
            "\n",
            "Chat: Name: John Smith, Email: john.smith@web.net, Age: fifty-two\n",
            "Extracted: {'raw': {'age': 52, 'email': 'john.smith@web.net', 'location': '', 'name': 'John Smith', 'phone': ''}, 'valid': True, 'errors': [], 'warnings': []}\n",
            "\n",
            "Chat: Contact: 555-1234, Location: Paris, France\n",
            "Extracted: {'raw': {'location': 'Paris, France', 'phone': '555-1234'}, 'valid': True, 'errors': [], 'warnings': []}\n",
            "An API error occurred: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=extract_user_info>{\"email\": \"test@example.com\"}<function>'}}\n",
            "Warning: Could not parse failed_generation string as JSON: <function=extract_user_info>{\"email\": \"test@example.com\"}<function>\n",
            "\n",
            "Chat: Email only: test@example.com\n",
            "Extracted: {'raw': {}, 'valid': True, 'errors': [], 'warnings': []}\n",
            "An API error occurred: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=extract_user_info>{\"age\": 30, \"location\": \"Berlin\"}<function>'}}\n",
            "Warning: Could not parse failed_generation string as JSON: <function=extract_user_info>{\"age\": 30, \"location\": \"Berlin\"}<function>\n",
            "\n",
            "Chat: Age: 30 years old, Location: Berlin\n",
            "Extracted: {'raw': {}, 'valid': True, 'errors': [], 'warnings': []}\n",
            "\n",
            "Chat: Name: Alice, Phone: 111-222-3333, Email: alice@mail.org, Location: Sydney, Age: 25\n",
            "Extracted: {'raw': {'age': 25, 'email': 'alice@mail.org', 'location': 'Sydney', 'name': 'Alice', 'phone': '111-222-3333'}, 'valid': True, 'errors': [], 'warnings': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this first\n",
        "!pip install --quiet openai jsonschema\n",
        "\n",
        "import os, json, re, getpass\n",
        "from jsonschema import Draft7Validator\n",
        "import openai\n",
        "\n",
        "# Securely set your Groq API key (in Colab, use getpass)\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Paste your GROQ API key (hidden): \").strip()\n",
        "\n",
        "# NOTE: we will create a *client instance* per-call below (same pattern you used)\n",
        "BASE_URL = \"https://api.groq.com/openai/v1\"\n"
      ],
      "metadata": {
        "id": "0YT6Gq5lohl3"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# conversation storage\n",
        "conversation = []\n",
        "\n",
        "def add_message(role, content):\n",
        "    conversation.append({\"role\": role, \"content\": content})\n",
        "\n",
        "# truncation helpers\n",
        "def truncate_by_turns(history_list, n):\n",
        "    return history_list[-n:]\n",
        "\n",
        "def truncate_by_chars(history_list, max_chars):\n",
        "    h = history_list.copy()\n",
        "    while sum(len(m['content']) for m in h) > max_chars and len(h) > 1:\n",
        "        h.pop(0)\n",
        "    return h\n",
        "\n",
        "def truncate_by_words(history_list, max_words):\n",
        "    h = history_list.copy()\n",
        "    def total_words(msgs): return sum(len(m['content'].split()) for m in msgs)\n",
        "    while total_words(h) > max_words and len(h) > 1:\n",
        "        h.pop(0)\n",
        "    return h\n"
      ],
      "metadata": {
        "id": "mR51odYyomJl"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quick test\n",
        "conversation = []\n",
        "add_message(\"user\", \"Hello\")\n",
        "add_message(\"assistant\", \"Hi — how can I help?\")\n",
        "add_message(\"user\", \"I need resume help.\")\n",
        "add_message(\"assistant\", \"Sure, share details.\")\n",
        "print(\"All:\", conversation)\n",
        "print(\"Last 2 turns:\", truncate_by_turns(conversation, 2))\n",
        "print(\"Chars truncated to 30:\", truncate_by_chars(conversation, 30))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHBXtC8VowT7",
        "outputId": "6106caa9-2d52-458d-8b5e-243738a27467"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All: [{'role': 'user', 'content': 'Hello'}, {'role': 'assistant', 'content': 'Hi — how can I help?'}, {'role': 'user', 'content': 'I need resume help.'}, {'role': 'assistant', 'content': 'Sure, share details.'}]\n",
            "Last 2 turns: [{'role': 'user', 'content': 'I need resume help.'}, {'role': 'assistant', 'content': 'Sure, share details.'}]\n",
            "Chars truncated to 30: [{'role': 'assistant', 'content': 'Sure, share details.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------ ConversationManager lightweight version  ------------------------------------------------------------------------------------------\n",
        "class ConversationManager:\n",
        "    def __init__(self, model_name=\"llama-3.1-8b-instant\", summarize_every_k=None, base_url=None, api_key=None):\n",
        "        self.messages = []\n",
        "        self.model_name = model_name\n",
        "        self.summarize_every_k = summarize_every_k\n",
        "        self.user_msg_count = 0\n",
        "        self.base_url = base_url # Store BASE_URL as instance variable\n",
        "        self.api_key = api_key # Store API key as instance variable\n",
        "\n",
        "    def add(self, role, content):\n",
        "        self.messages.append({\"role\": role, \"content\": content})\n",
        "        if role == \"user\":\n",
        "            self.user_msg_count += 1\n",
        "            if self.summarize_every_k and (self.user_msg_count % self.summarize_every_k == 0):\n",
        "                summary = self.summarize_history()\n",
        "                # replace history with a summary message\n",
        "                self.messages = [{\"role\":\"system\", \"content\":\"Conversation summary\"},\n",
        "                                 {\"role\":\"assistant\",\"content\": summary}]\n",
        "                # reset user_msg_count (optional) or keep counting; here we'll keep counting\n",
        "\n",
        "    def summarize_history(self, max_tokens=250):\n",
        "        if not self.api_key:\n",
        "            print(\"Error: API key is not set in ConversationManager.\")\n",
        "            return \"Summary unavailable: API key missing.\"\n",
        "\n",
        "        # Build a compact history text\n",
        "        history_text = \"\\n\".join(f\"{m['role']}: {m['content']}\" for m in self.messages)\n",
        "        prompt = (\"Summarize the conversation below in 3-6 short bullet points or 1 short paragraph. \"\n",
        "                  \"Keep it concise and list any important facts (names, numbers, requests):\\n\\n\" + history_text)\n",
        "        # create client and call Groq endpoint using instance variable\n",
        "        # Use the stored API key\n",
        "        client = openai.OpenAI(api_key=self.api_key, base_url=self.base_url)\n",
        "        resp = client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=[{\"role\":\"system\",\"content\":\"You are a summarization assistant.\"},\n",
        "                      {\"role\":\"user\",\"content\":prompt}],\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=0.1\n",
        "        )\n",
        "        # Extract text reliably\n",
        "        try:\n",
        "            text = resp.choices[0].message.content\n",
        "        except Exception:\n",
        "            text = getattr(resp, \"output_text\", str(resp))\n",
        "        return text.strip()\n",
        "\n",
        "    # Truncation methods moved inside the class\n",
        "    def truncate_by_turns(self, n):\n",
        "        self.messages = self.messages[-n:]\n",
        "\n",
        "    def truncate_by_chars(self, max_chars):\n",
        "        h = self.messages.copy()\n",
        "        while sum(len(m['content']) for m in h) > max_chars and len(h) > 1:\n",
        "            h.pop(0)\n",
        "        self.messages = h\n",
        "\n",
        "    def truncate_by_words(self, max_words):\n",
        "        h = self.messages.copy()\n",
        "        def total_words(msgs): return sum(len(m['content'].split()) for m in msgs)\n",
        "        while total_words(h) > max_words and len(h) > 1:\n",
        "            h.pop(0)\n",
        "        self.messages = h"
      ],
      "metadata": {
        "id": "nwYWZ-61o48w"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = ConversationManager(summarize_every_k=3, base_url=BASE_URL)  # summarize after every 3 user messages\n",
        "cm.add(\"user\",\"Hi I need resume help\")\n",
        "cm.add(\"assistant\",\"Sure, tell me your experience\")\n",
        "cm.add(\"user\",\"I worked on ML image classifier\")\n",
        "# After the 2nd user addition (3rd user? here user_count increments when role=='user') this should trigger summary\n",
        "cm.add(\"assistant\",\"Thanks, noted\")\n",
        "cm.add(\"user\",\"Also need LinkedIn summary\")\n",
        "print(\"History after operations:\", cm.messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLJ7-tcCo-01",
        "outputId": "6a2c072a-bbbf-4cdf-e1a2-eae804514682"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: API key is not set in ConversationManager.\n",
            "History after operations: [{'role': 'system', 'content': 'Conversation summary'}, {'role': 'assistant', 'content': 'Summary unavailable: API key missing.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, re, getpass\n",
        "from jsonschema import Draft7Validator\n",
        "import openai  # Ensure it's imported\n",
        "\n",
        "# Securely set your Groq API key\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Paste your GROQ API key (hidden): \").strip()\n",
        "\n",
        "# Define BASE_URL at the top-level so it's accessible\n",
        "BASE_URL = \"https://api.groq.com/openai/v1\"\n",
        "\n",
        "# Schema for function calling - Modified to allow null for all optional fields\n",
        "schema = {\n",
        "    \"name\": \"extract_user_info\",\n",
        "    \"description\": \"Extract name, email, phone, location and age from free text\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"name\": {\"oneOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}]}, # Allow null for name\n",
        "            \"email\": {\"oneOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}]}, # Allow null for email\n",
        "            \"phone\": {\"oneOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}]}, # Allow null for phone\n",
        "            \"location\": {\"oneOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}]}, # Allow null for location\n",
        "            # Allow age to be either integer or null\n",
        "            \"age\": {\"oneOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}]}\n",
        "        },\n",
        "        \"required\": []  # All fields are optional\n",
        "    }\n",
        "}\n",
        "\n",
        "def extract_info(chat_text, model_name=\"llama-3.1-8b-instant\", base_url=BASE_URL):\n",
        "    client = openai.OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"], base_url=base_url)\n",
        "    parsed = {} # Initialize parsed data\n",
        "    warnings = [] # Initialize warnings\n",
        "    api_error = None # Variable to store API error if one occurs\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a JSON extractor that uses function-calling. Extract the user's name, email, phone, location, and age from the provided text. If a piece of information is not present in the text, omit that field from the JSON or set its value to null according to the function schema. Prioritize extracting the information accurately.\"}, # Refined prompt\n",
        "                {\"role\": \"user\", \"content\": f\"Text to extract from: {chat_text}\"}\n",
        "            ],\n",
        "            functions=[schema],\n",
        "            function_call={\"name\": \"extract_user_info\"},\n",
        "            temperature=0.0,\n",
        "            max_tokens=200\n",
        "        )\n",
        "\n",
        "        # Extract function arguments from successful response\n",
        "        if response.choices and response.choices[0].message.function_call:\n",
        "            func_args = response.choices[0].message.function_call.arguments\n",
        "            if isinstance(func_args, str):\n",
        "                try:\n",
        "                    parsed = json.loads(func_args)\n",
        "                except json.JSONDecodeError:\n",
        "                    warnings.append(f\"Could not parse function arguments string as JSON: {func_args}\")\n",
        "                    parsed = {} # Set to empty dict on failure\n",
        "            elif isinstance(func_args, dict):\n",
        "                parsed = func_args\n",
        "            else:\n",
        "                warnings.append(f\"Unexpected type for function arguments: {type(func_args)}. Raw value: {func_args}\")\n",
        "                parsed = {} # Set to empty dict for unexpected types\n",
        "\n",
        "    except openai.BadRequestError as e:\n",
        "        api_error = e # Store the API error\n",
        "        print(f\"Caught BadRequestError: {e}\")\n",
        "        error_details = {\"message\": str(e)}\n",
        "        try:\n",
        "            error_response = json.loads(str(e).split(\" - \")[1].strip())\n",
        "            if \"error\" in error_response:\n",
        "                error_details = error_response[\"error\"]\n",
        "        except (IndexError, json.JSONDecodeError):\n",
        "            pass # Keep default message if parsing fails\n",
        "\n",
        "        # Check specifically for the \"Failed to call a function\" error with empty failed_generation\n",
        "        if \"Failed to call a function\" in str(e) and \"failed_generation\" in str(error_details) and not error_details.get(\"failed_generation\", \"\").strip():\n",
        "             print(\"Note: Caught 'Failed to call a function' error with empty failed_generation. Extraction failed.\")\n",
        "             # Return a failure result immediately for this specific error\n",
        "             return {\"raw\": {}, \"valid\": False, \"errors\": [f\"API Error: Failed to extract information. Model did not return a valid function call ({error_details.get('message', 'Unknown error')}).\"], \"warnings\": warnings}\n",
        "\n",
        "\n",
        "        # If failed_generation was not empty, try to parse it from error details\n",
        "        failed_generation_match = re.search(r\"'failed_generation': '(.*?)'\", str(error_details))\n",
        "        failed_generation_str = failed_generation_match.group(1) if failed_generation_match else None\n",
        "\n",
        "        if failed_generation_str:\n",
        "             json_like_match = re.search(r\"\\{[\\s\\S]*\\}\", failed_generation_str)\n",
        "             json_like_str = json_like_match.group(0) if json_like_match else \"{}\"\n",
        "\n",
        "             try:\n",
        "                 parsed = json.loads(json_like_str)\n",
        "                 print(f\"Successfully extracted and parsed data from failed_generation: {parsed}\")\n",
        "             except json.JSONDecodeError:\n",
        "                  warnings.append(f\"Could not parse extracted JSON-like string from failed_generation error: {json_like_str}\")\n",
        "                  parsed = {} # Set to empty dict on failure\n",
        "        else:\n",
        "             # If it was a BadRequestError but not the specific empty failed_generation,\n",
        "             # and no failed_generation string was found, initialize parsed as empty.\n",
        "             parsed = {}\n",
        "             warnings.append(f\"BadRequestError occurred without a parsable failed_generation field: {e}\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        api_error = e # Store the unexpected error\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        parsed = {} # Set to empty dict for unexpected errors\n",
        "        warnings.append(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "\n",
        "    # Clean up and cast fields to correct types based on schema (applied to both success and error parsing)\n",
        "    cleaned_parsed = {}\n",
        "    for key, value in parsed.items():\n",
        "        if key in schema[\"parameters\"][\"properties\"]:\n",
        "            expected_schema_type = schema[\"parameters\"][\"properties\"][key]\n",
        "            if key == \"age\" and \"oneOf\" in expected_schema_type and {\"type\": \"null\"} in expected_schema_type[\"oneOf\"]:\n",
        "                 # If age can be null, accept None or null from model\n",
        "                 if value is None or value == \"null\":\n",
        "                      cleaned_parsed[key] = None\n",
        "                 elif isinstance(value, (int, float)):\n",
        "                      cleaned_parsed[key] = int(value)\n",
        "                 elif isinstance(value, str) and value.isdigit():\n",
        "                      cleaned_parsed[key] = int(value)\n",
        "                 elif value is not None and value != \"\":\n",
        "                      warnings.append(f\"Could not cast value '{value}' for key '{key}' to integer or null. Skipping.\")\n",
        "            elif expected_schema_type.get(\"type\") == \"integer\":\n",
        "                # Attempt to cast to integer, handle errors and empty strings for standard integers\n",
        "                if isinstance(value, (int, float)):\n",
        "                     cleaned_parsed[key] = int(value)\n",
        "                elif isinstance(value, str) and value.isdigit():\n",
        "                     cleaned_parsed[key] = int(value)\n",
        "                elif value is not None and value != \"\":\n",
        "                     warnings.append(f\"Could not cast value '{value}' for key '{key}' to integer. Skipping.\")\n",
        "            elif \"oneOf\" in expected_schema_type and {\"type\": \"string\"} in expected_schema_type[\"oneOf\"] and {\"type\": \"null\"} in expected_schema_type[\"oneOf\"]:\n",
        "                # Handle fields that can be string or null\n",
        "                if value is None or value == \"null\":\n",
        "                     cleaned_parsed[key] = None\n",
        "                elif value is not None:\n",
        "                     cleaned_parsed[key] = str(value)\n",
        "            elif expected_schema_type.get(\"type\") == \"string\":\n",
        "                 # Ensure string type, convert non-string values if possible\n",
        "                 if value is not None:\n",
        "                      cleaned_parsed[key] = str(value)\n",
        "            else:\n",
        "                # Keep other types as they are or handle specifically if needed\n",
        "                cleaned_parsed[key] = value\n",
        "        else:\n",
        "             # Include keys not in schema if desired, or skip\n",
        "             cleaned_parsed[key] = value\n",
        "\n",
        "\n",
        "    # Validate schema against the cleaned data\n",
        "    validator = Draft7Validator(schema[\"parameters\"])\n",
        "    errors = [e.message for e in sorted(validator.iter_errors(cleaned_parsed), key=lambda x: x.path)]\n",
        "\n",
        "    # If there were API errors but the data is otherwise valid based on schema,\n",
        "    # include the API error in the errors list for clarity.\n",
        "    if api_error and not errors: # Check if an API error occurred AND there are no schema validation errors\n",
        "         errors.append(f\"API Error during extraction: {str(api_error)}. Extracted data is valid based on schema.\")\n",
        "    # Also add warnings as errors if there are no schema validation errors and no API errors\n",
        "    elif not errors and not api_error and warnings:\n",
        "        errors.extend(warnings)\n",
        "        warnings = [] # Clear warnings if they are moved to errors\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"raw\": cleaned_parsed,\n",
        "        \"valid\": len(errors) == 0,\n",
        "        \"errors\": errors,\n",
        "        \"warnings\": warnings # Keep separate warnings for non-critical issues\n",
        "    }\n",
        "\n",
        "\n",
        "# === Test on sample inputs ===\n",
        "samples = [\n",
        "    \"Hi, my name is Ravi. email: ravi123@gmail.com phone: 9876543210 location: Hyderabad age 23\",\n",
        "    \"Hello, I'm Priya — priya.jobs@mail.com. I live in Bengaluru. Age: 29.\",\n",
        "    \"Contact Amit — phone 070-555-1234. No email given. Based in Mumbai.\"\n",
        "]\n",
        "\n",
        "print(\"Testing with sample inputs:\")\n",
        "for s in samples:\n",
        "    out = extract_info(s)\n",
        "    print(\"\\nChat:\", s)\n",
        "    print(\"Extracted:\", out[\"raw\"])\n",
        "    print(\"Valid?:\", out[\"valid\"])\n",
        "    if out[\"errors\"]:\n",
        "        print(\"Errors:\", out[\"errors\"])\n",
        "    if out[\"warnings\"]:\n",
        "        print(\"Warnings:\", out[\"warnings\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nTy9rU-pA8m",
        "outputId": "229698bc-d1c3-4de6-97d2-1b88d4f3a751"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing with sample inputs:\n",
            "\n",
            "Chat: Hi, my name is Ravi. email: ravi123@gmail.com phone: 9876543210 location: Hyderabad age 23\n",
            "Extracted: {'text': 'Hi, my name is Ravi. email: ravi123@gmail.com phone: 9876543210 location: Hyderabad age 23'}\n",
            "Valid?: True\n",
            "\n",
            "Chat: Hello, I'm Priya — priya.jobs@mail.com. I live in Bengaluru. Age: 29.\n",
            "Extracted: {'age': 29, 'email': 'priya.jobs@mail.com', 'location': 'Bengaluru', 'name': 'Priya', 'phone': None}\n",
            "Valid?: True\n",
            "\n",
            "Chat: Contact Amit — phone 070-555-1234. No email given. Based in Mumbai.\n",
            "Extracted: {'age': None, 'email': None, 'location': 'Mumbai', 'name': 'Amit', 'phone': '070-555-1234'}\n",
            "Valid?: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [\n",
        "    \"Hi, my name is Ravi. email: ravi123@gmail.com phone: 9876543210 location: Hyderabad age 23\",\n",
        "    \"Hello, I'm Priya — priya.jobs@mail.com. I live in Bengaluru. Age: 29.\",\n",
        "    \"Contact Amit — phone 070-555-1234. No email given. Based in Mumbai.\"\n",
        "]\n",
        "\n",
        "for s in samples:\n",
        "    out = extract_info(s)\n",
        "    print(\"\\nChat:\", s)\n",
        "    print(\"Extracted:\", out[\"raw\"])\n",
        "    print(\"Valid?:\", out[\"valid\"])\n",
        "    if out[\"errors\"]:\n",
        "        print(\"Validation errors:\", out[\"errors\"])\n"
      ],
      "metadata": {
        "id": "Pgwwv6BLyR9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b2713dd-5db9-4919-81c5-9c5eef13cf21"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chat: Hi, my name is Ravi. email: ravi123@gmail.com phone: 9876543210 location: Hyderabad age 23\n",
            "Extracted: {'text': 'Hi, my name is Ravi. email: ravi123@gmail.com phone: 9876543210 location: Hyderabad age 23'}\n",
            "Valid?: True\n",
            "\n",
            "Chat: Hello, I'm Priya — priya.jobs@mail.com. I live in Bengaluru. Age: 29.\n",
            "Extracted: {'age': 29, 'email': 'priya.jobs@mail.com', 'location': 'Bengaluru', 'name': 'Priya', 'phone': None}\n",
            "Valid?: True\n",
            "\n",
            "Chat: Contact Amit — phone 070-555-1234. No email given. Based in Mumbai.\n",
            "Extracted: {'age': None, 'email': None, 'location': 'Mumbai', 'name': 'Amit', 'phone': '070-555-1234'}\n",
            "Valid?: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cfdeb60",
        "outputId": "d584cb11-94f2-4de1-a41d-9cfc4c3d6f25"
      },
      "source": [
        "# Additional test cases for the extract_info function\n",
        "\n",
        "diverse_samples = [\n",
        "    \"My name is Jane Doe, email: jane.doe@example.com\", # Missing phone, location, age\n",
        "    \"Lives in London, phone: +44 20 1234 5678\", # Missing name, email, age\n",
        "    \"Age is 45\", # Missing name, email, phone, location\n",
        "    \"No info here.\", # No information to extract\n",
        "    \"Name: John Smith, Email: john.smith@web.net, Age: fifty-two\", # Age as text\n",
        "    \"Contact: 555-1234, Location: Paris, France\", # Missing name, email, age, different phone format\n",
        "    \"Email only: test@example.com\", # Only email provided\n",
        "    \"Age: 30 years old, Location: Berlin\", # Age with extra text\n",
        "    \"Name: Alice, Phone: 111-222-3333, Email: alice@mail.org, Location: Sydney, Age: 25\" # All fields\n",
        "]\n",
        "\n",
        "print(\"Testing with diverse inputs:\")\n",
        "for s in diverse_samples:\n",
        "    out = extract_info(s) # Use the extract_info from 3nTy9rU-pA8m\n",
        "    print(\"\\nChat:\", s)\n",
        "    print(\"Extracted:\", out[\"raw\"])\n",
        "    print(\"Valid?:\", out[\"valid\"])\n",
        "    if out[\"errors\"]:\n",
        "        print(\"Validation errors:\", out[\"errors\"])\n",
        "    if out[\"warnings\"]:   # NEW\n",
        "        print(\"Warnings:\", out[\"warnings\"])"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing with diverse inputs:\n",
            "\n",
            "Chat: My name is Jane Doe, email: jane.doe@example.com\n",
            "Extracted: {'age': None, 'email': 'jane.doe@example.com', 'location': None, 'name': 'Jane Doe', 'phone': None}\n",
            "Valid?: True\n",
            "\n",
            "Chat: Lives in London, phone: +44 20 1234 5678\n",
            "Extracted: {'age': None, 'email': None, 'location': 'London', 'name': None, 'phone': '+44 20 1234 5678'}\n",
            "Valid?: True\n",
            "\n",
            "Chat: Age is 45\n",
            "Extracted: {'age': 45, 'email': None, 'location': None, 'name': None, 'phone': None}\n",
            "Valid?: True\n",
            "\n",
            "Chat: No info here.\n",
            "Extracted: {'age': None, 'email': None, 'location': None, 'name': None, 'phone': None}\n",
            "Valid?: True\n",
            "\n",
            "Chat: Name: John Smith, Email: john.smith@web.net, Age: fifty-two\n",
            "Extracted: {'age': 52, 'email': 'john.smith@web.net', 'location': None, 'name': 'John Smith', 'phone': None}\n",
            "Valid?: True\n",
            "\n",
            "Chat: Contact: 555-1234, Location: Paris, France\n",
            "Extracted: {'age': None, 'email': None, 'location': 'Paris, France', 'name': None, 'phone': '555-1234'}\n",
            "Valid?: True\n",
            "\n",
            "Chat: Email only: test@example.com\n",
            "Extracted: {'age': None, 'email': 'test@example.com', 'location': None, 'name': None, 'phone': None}\n",
            "Valid?: True\n",
            "\n",
            "Chat: Age: 30 years old, Location: Berlin\n",
            "Extracted: {'age': 30, 'email': None, 'location': 'Berlin', 'name': None, 'phone': None}\n",
            "Valid?: True\n",
            "\n",
            "Chat: Name: Alice, Phone: 111-222-3333, Email: alice@mail.org, Location: Sydney, Age: 25\n",
            "Extracted: {'age': 25, 'email': 'alice@mail.org', 'location': 'Sydney', 'name': 'Alice', 'phone': '111-222-3333'}\n",
            "Valid?: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DEMO: Task 1 — conversation samples & k-th summarization\n",
        "# Pass the API key to the ConversationManager constructor\n",
        "cm = ConversationManager(model_name=MODEL, summarize_every_k=3, base_url=BASE_URL, api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "# feed sample conversation lines (user + simulated assistant replies)\n",
        "samples = [\n",
        "    (\"user\", \"Hi — I want help with my resume.\"),\n",
        "    (\"assistant\", \"Sure — what is your experience?\"),\n",
        "    (\"user\", \"I have 2 years in Python and ML internship.\"),\n",
        "    (\"assistant\", \"Great, any projects?\"),\n",
        "    (\"user\", \"Built an image classifier project with 85% accuracy.\"),\n",
        "    (\"assistant\", \"Nice — metrics matter.\"),\n",
        "]\n",
        "\n",
        "for role, text in samples:\n",
        "    cm.add(role, text)\n",
        "    print(\"Added:\", role, text)\n",
        "    print(\"History length:\", len(cm.messages))\n",
        "    # Corrected: access messages attribute directly instead of calling non-existent method\n",
        "    print(\"History preview:\", cm.messages[:300]) # Displaying first 300 characters of the message list representation\n",
        "    print(\"---\")\n",
        "\n",
        "print(\"\\nNow demonstrate truncation:\")\n",
        "# rebuild a bigger history\n",
        "# Pass the API key to the ConversationManager constructor\n",
        "cm2 = ConversationManager(model_name=MODEL, base_url=BASE_URL, api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "for r,t in samples*3:\n",
        "    cm2.add(r, t)\n",
        "print(\"Original turns:\", len(cm2.messages))\n",
        "# Assuming truncate_by_turns is defined in ConversationManager and modifies in place\n",
        "cm2.truncate_by_turns(4)\n",
        "print(\"After truncate_by_turns(4): turns =\", len(cm2.messages))\n",
        "# char truncation\n",
        "# Pass the API key to the ConversationManager constructor\n",
        "cm3 = ConversationManager(model_name=MODEL, base_url=BASE_URL, api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "for r,t in samples*3:\n",
        "    cm3.add(r,t)\n",
        "print(\"Original char count:\", sum(len(m['content']) for m in cm3.messages))\n",
        "# Assuming truncate_by_chars is defined in ConversationManager and modifies in place\n",
        "cm3.truncate_by_chars(120)\n",
        "print(\"After truncate_by_chars(120) char count:\", sum(len(m['content']) for m in cm3.messages))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p49_n0JLXvFE",
        "outputId": "21a59912-2b8e-4b8e-b8fd-c64af525e8c1"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added: user Hi — I want help with my resume.\n",
            "History length: 1\n",
            "History preview: [{'role': 'user', 'content': 'Hi — I want help with my resume.'}]\n",
            "---\n",
            "Added: assistant Sure — what is your experience?\n",
            "History length: 2\n",
            "History preview: [{'role': 'user', 'content': 'Hi — I want help with my resume.'}, {'role': 'assistant', 'content': 'Sure — what is your experience?'}]\n",
            "---\n",
            "Added: user I have 2 years in Python and ML internship.\n",
            "History length: 3\n",
            "History preview: [{'role': 'user', 'content': 'Hi — I want help with my resume.'}, {'role': 'assistant', 'content': 'Sure — what is your experience?'}, {'role': 'user', 'content': 'I have 2 years in Python and ML internship.'}]\n",
            "---\n",
            "Added: assistant Great, any projects?\n",
            "History length: 4\n",
            "History preview: [{'role': 'user', 'content': 'Hi — I want help with my resume.'}, {'role': 'assistant', 'content': 'Sure — what is your experience?'}, {'role': 'user', 'content': 'I have 2 years in Python and ML internship.'}, {'role': 'assistant', 'content': 'Great, any projects?'}]\n",
            "---\n",
            "Added: user Built an image classifier project with 85% accuracy.\n",
            "History length: 2\n",
            "History preview: [{'role': 'system', 'content': 'Conversation summary'}, {'role': 'assistant', 'content': \"Here's a summary of the conversation:\\n\\n- The user is seeking help with their resume.\\n- They have 2 years of experience in Python and Machine Learning (ML) internships.\\n- They have a project experience with an image classifier that achieved 85% accuracy.\"}]\n",
            "---\n",
            "Added: assistant Nice — metrics matter.\n",
            "History length: 3\n",
            "History preview: [{'role': 'system', 'content': 'Conversation summary'}, {'role': 'assistant', 'content': \"Here's a summary of the conversation:\\n\\n- The user is seeking help with their resume.\\n- They have 2 years of experience in Python and Machine Learning (ML) internships.\\n- They have a project experience with an image classifier that achieved 85% accuracy.\"}, {'role': 'assistant', 'content': 'Nice — metrics matter.'}]\n",
            "---\n",
            "\n",
            "Now demonstrate truncation:\n",
            "Original turns: 18\n",
            "After truncate_by_turns(4): turns = 4\n",
            "Original char count: 600\n",
            "After truncate_by_chars(120) char count: 94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wrap-up\n",
        "\n",
        "## Task 1 — Conversation Management & Summarization\n",
        "- Implemented ConversationManager to keep running history, truncate by turns/characters/words, and summarize every k-th user message (demoed with k=3).\n",
        "- Verified with multiple simulated exchanges.\n",
        "\n",
        "## Task 2 — JSON Schema Extraction\n",
        "- Created `extract_user_info` schema and implemented `extract_info()` using Groq OpenAI-compatible client with function calling.\n",
        "- Implemented robust parsing, normalization, regex fallback for phone/email, and a text-JSON fallback when function-calling fails.\n",
        "- Demonstrated parsing 3+ samples and validated outputs with a small evaluation routine.\n",
        "\n",
        "## Limitations\n",
        "- Small/sparse inputs may still lead to partial extraction — fallback mitigates most cases.\n",
        "- For final submission, use a larger Groq model for higher reliability.\n",
        "\n"
      ],
      "metadata": {
        "id": "yzr_ctaWW6SN"
      }
    }
  ]
}